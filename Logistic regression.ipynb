{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606b0053-83e9-4ac1-b04b-8fff213ccd73",
   "metadata": {},
   "source": [
    "# __Logistic Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fcd50-a208-44db-a3df-136748ff9d1e",
   "metadata": {},
   "source": [
    "### __Theoretical__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f31f63-4aff-49aa-8135-677c05d7d510",
   "metadata": {},
   "source": [
    "### 1.What is Logistic Regression, and how does it differ from Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729ef71-a87c-4d33-b686-034957fa00e8",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical method used for binary classification tasks. Unlike Linear Regression, which predicts continuous outcomes, Logistic Regression predicts probabilities and classifies outcomes into categories using a sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9f38a-7d75-45f4-ad5c-1bf5ced469a8",
   "metadata": {},
   "source": [
    "### 2. What is the mathematical equation of Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313de3fd-0ae7-46e8-a07a-142d4d8af069",
   "metadata": {},
   "source": [
    "The equation is:\n",
    "P(y=1|x)=1/1+e^-(β0+β1x1+β2x2+...+βnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985df294-dbc1-4546-b9b9-013a5b7340f6",
   "metadata": {},
   "source": [
    "### 3. Why do we use the Sigmoid function in Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c18b8a-a890-4d0d-b904-10b97f3fa397",
   "metadata": {},
   "source": [
    "\n",
    "The Sigmoid function maps any real value into a probability between 0 and 1, making it ideal for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3da95-4dea-4b7b-8be7-4f0897b818da",
   "metadata": {},
   "source": [
    "### 4. What is the cost function of Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4ff13-dc6f-4b91-9c33-c326606de6f6",
   "metadata": {},
   "source": [
    "\n",
    "The cost function for logistic regression is defined as follows:\n",
    "\n",
    "\\[ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right] \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749804b4-77d7-46b4-8373-9cabecb3c15a",
   "metadata": {},
   "source": [
    "### 5. What is Regularization in Logistic Regression? Why is it needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb876fc-5e83-4706-9159-1a5f52109f8f",
   "metadata": {},
   "source": [
    "Regularization prevents overfitting by penalizing large coefficients. It helps improve the generalization of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01367071-2e54-4f44-ace6-fac6546582da",
   "metadata": {},
   "source": [
    "### 6. Explain the difference between Lasso, Ridge, and Elastic Net regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802b82d-b3bd-49f0-b4f5-147550e5ba7a",
   "metadata": {},
   "source": [
    "- Lasso (L1 Regularization): Shrinks some coefficients to zero for feature selection.\n",
    "\n",
    "- Ridge (L2 Regularization): Shrinks coefficients but doesn’t reduce them to zero.\n",
    "\n",
    "- Elastic Net: A combination of L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbe8ca-22ee-4461-8683-1d37e0365422",
   "metadata": {},
   "source": [
    "### 7. When should we use Elastic Net instead of Lasso or Ridge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7e992-1aba-41db-a2f4-154d651e3f46",
   "metadata": {},
   "source": [
    "Use Elastic Net when there are multiple correlated features, combining Lasso's feature selection and Ridge's shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cd9b4-636c-46c4-8c14-e549954037c1",
   "metadata": {},
   "source": [
    "### 8. What is the impact of the regularization parameter (λ)) in Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f178c463-994c-4593-9b42-f9c2228b3f0a",
   "metadata": {},
   "source": [
    "A larger λ increases regularization strength, penalizing larger coefficients and reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62154a6-a1e8-4dde-81d3-d468db33b156",
   "metadata": {},
   "source": [
    "### 9. What are the key assumptions of Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef6efa-0f3d-48e3-94cf-94ab3d5e62aa",
   "metadata": {},
   "source": [
    "- Binary outcome variable.\n",
    "\n",
    "- No multicollinearity among features.\n",
    "\n",
    "- Large sample size.\n",
    "\n",
    "- Linearity between independent variables and log odds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0964ee9-c2ef-4b47-9da6-3b724d11e756",
   "metadata": {},
   "source": [
    "### 10. What are some alternatives to Logistic Regression for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e6709-f75d-4098-9b32-57ad633357d2",
   "metadata": {},
   "source": [
    "- Decision Trees\n",
    "\n",
    "- Random Forests\n",
    "\n",
    "- Support Vector Machines (SVM)\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e9eca-16fd-445c-8201-5f05b1966ca1",
   "metadata": {},
   "source": [
    "### 11. What are Classification Evaluation Metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62759b85-c52c-45f5-8485-c3d4706b1df0",
   "metadata": {},
   "source": [
    "- Accuracy\n",
    "\n",
    "- Precision\n",
    "\n",
    "- Recall\n",
    "\n",
    "- F1-Score\n",
    "\n",
    "- ROC-AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ee6b9-fb79-4ad3-8035-a29dff43c56f",
   "metadata": {},
   "source": [
    "### 12. How does class imbalance affect Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a69034-e6a9-402b-ae5e-c60216d163b5",
   "metadata": {},
   "source": [
    "It can lead to biased predictions towards the majority class. Using class weights or resampling techniques helps mitigate this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d75d2f-f10d-4ff5-a499-a3de7b41cc2a",
   "metadata": {},
   "source": [
    "### 13. What is Hyperparameter Tuning in Logistic Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c781872-3166-4ee8-aef4-7dcd37cb3035",
   "metadata": {},
   "source": [
    "### 14. What are different solvers in Logistic Regression? Which one should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6f58d-77ae-4f5c-bd06-fba7abd5c165",
   "metadata": {},
   "source": [
    "- liblinear: Good for small datasets.\n",
    "\n",
    "- saga: Supports Elastic Net regularization.\n",
    "\n",
    "- lbfgs: Good for large datasets.\n",
    "\n",
    "- newton-cg: Suitable for multinomial loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e40cc2-f987-40fe-adc3-3f348f16ab30",
   "metadata": {},
   "source": [
    "### 15. How is Logistic Regression extended for multiclass classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b777cee-09cb-48c5-b14a-8a260813a52b",
   "metadata": {},
   "source": [
    "Using methods like One-vs-Rest (OvR) or Softmax Regression for handling multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bd405-03b3-4d0d-8479-e007d5f5e719",
   "metadata": {},
   "source": [
    "### 16. What are the advantages and disadvantages of Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b54e2-6eac-4625-9455-b892e363d145",
   "metadata": {},
   "source": [
    "- Advantages: Simple, interpretable, fast.\n",
    "\n",
    "- Disadvantages: Limited to linear decision boundaries, sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36254c-1548-4490-b2c6-a3de0d84771a",
   "metadata": {},
   "source": [
    "### 17. What are some use cases of Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e209bd7-6d7b-47de-a6f2-0becd81ad1fd",
   "metadata": {},
   "source": [
    "- Spam detection\n",
    "\n",
    "- Fraud detection\n",
    "\n",
    "- Customer churn prediction\n",
    "\n",
    "- Medical diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117e959-53c5-4a96-af0a-5f1427071a96",
   "metadata": {},
   "source": [
    "### 18. What is the difference between Softmax Regression and Logistic Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519b1a8-6ba4-433e-b2bf-1486a080b787",
   "metadata": {},
   "source": [
    "Softmax handles multiclass classification, whereas Logistic Regression is typically used for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a51be1-3d04-4ad8-a6a0-3778120645ac",
   "metadata": {},
   "source": [
    "### 19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98f0a0-26d7-4f2e-a68b-53dc51f2ddc7",
   "metadata": {},
   "source": [
    "- OvR: When classes are imbalanced.\n",
    "\n",
    "- Softmax: When classes are mutually exclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13124f6d-1ab0-4f27-9fa7-fed4262c6156",
   "metadata": {},
   "source": [
    "### 20. How do we interpret coefficients in Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18d5ed-dfb5-422a-b562-3ae0db449a66",
   "metadata": {},
   "source": [
    "Each coefficient represents the change in log odds of the outcome for a one-unit change in the predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7af6a1-31ea-4b2d-9cbf-6fd67473fe03",
   "metadata": {},
   "source": [
    "### __Practical__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcfe0ab-8b31-4b51-81ee-30663c0c6530",
   "metadata": {},
   "source": [
    "### 1.Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd500a6c-7b3a-4cb9-ad90-c61fb2b0c7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.08532423208191127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your dataset file name\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('discounted_price', axis=1)  # Replace 'target' with your actual target column\n",
    "y = df['discounted_price']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d01155-350d-472f-afba-1c5c3e25a383",
   "metadata": {},
   "source": [
    "### 2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a529075-6956-4323-9463-bd77b8a349e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularization (Lasso) Model Accuracy: 0.17747440273037543\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('discounted_price', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['actual_price']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Logistic Regression with L1 Regularization (Lasso)\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"L1 Regularization (Lasso) Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fd823-20b5-4036-828d-b9c90e13c946",
   "metadata": {},
   "source": [
    "### 3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4857be-fbae-40b4-a991-4f6a7e70fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularization (Ridge) Model Accuracy: 0.20136518771331058\n",
      "\n",
      "Model Coefficients:\n",
      "                 Feature  Coefficient\n",
      "0            product_id     0.002690\n",
      "1          product_name    -0.016113\n",
      "2              category     0.001144\n",
      "3      discounted_price    -0.000947\n",
      "4          actual_price     0.005354\n",
      "5   discount_percentage     0.000738\n",
      "6                rating     0.000010\n",
      "7          rating_count     0.006789\n",
      "8         about_product     0.014775\n",
      "9               user_id    -0.007825\n",
      "10            user_name     0.015989\n",
      "11            review_id    -0.003824\n",
      "12         review_title    -0.016667\n",
      "13             img_link     0.023446\n",
      "14         product_link    -0.018992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model with L2 Regularization (Ridge)\n",
    "ridge_model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"L2 Regularization (Ridge) Model Accuracy:\", accuracy)\n",
    "\n",
    "# Print model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': ridge_model.coef_[0]\n",
    "})\n",
    "print(\"\\nModel Coefficients:\\n\", coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7f1dc-b5a7-4182-828a-69695ecc7cca",
   "metadata": {},
   "source": [
    "### 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2156b3e-cd61-4790-8f83-eb713cc4b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regularization Model Accuracy: 0.1945392491467577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model with Elastic Net Regularization\n",
    "elastic_net_model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = elastic_net_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Elastic Net Regularization Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dcaeb-a24c-44c0-bee5-f0bf6b9296f6",
   "metadata": {},
   "source": [
    "### 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4310d1f5-ed98-4744-aa1e-5fe318bac813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification (OvR) Model Accuracy: 0.16382252559726962\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model for multiclass classification using One-vs-Rest (OvR)\n",
    "multiclass_model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "multiclass_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = multiclass_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Multiclass Classification (OvR) Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc8a40-a0bc-4364-aad3-d378b748474a",
   "metadata": {},
   "source": [
    "### 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f8a1e5-bf30-4102-80e9-23eec71c26a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m],  \u001b[38;5;66;03m# Regularization strength\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m],       \u001b[38;5;66;03m# Regularization type\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m]        \u001b[38;5;66;03m# Solver that supports both L1 and L2\u001b[39;00m\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize and apply GridSearchCV\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print best parameters and corresponding accuracy\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],       # Regularization type\n",
    "    'solver': ['liblinear']        # Solver that supports both L1 and L2\n",
    "}\n",
    "\n",
    "# Initialize and apply GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Set Accuracy with Best Parameters:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96562a4-3394-46a5-96f5-71ded8e7de78",
   "metadata": {},
   "source": [
    "### 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ced751-bf83-4bc9-a89f-b19205475e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate accuracy scores\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Print each fold's accuracy and the average accuracy\n",
    "print(\"Accuracy for each fold:\", scores)\n",
    "print(\"Average Accuracy across folds:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4838e-1763-40a8-b6c6-53635ddcb35d",
   "metadata": {},
   "source": [
    "### 8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfbb88-ff68-4b8d-af20-4543495aac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4df8c-d8d4-44f1-a8bb-e6207a04e787",
   "metadata": {},
   "source": [
    "### 9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa17a634-037a-40ed-bac1-4dd1933d35d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Apply RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     29\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     30\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m     31\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,  \u001b[38;5;66;03m# Number of parameter settings sampled\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,       \u001b[38;5;66;03m# 5-fold cross-validation\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     34\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Fit the model using random search\u001b[39;00m\n\u001b[0;32m     38\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter distribution for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'C': np.logspace(-3, 2, 10),  # Regularization strength from 0.001 to 100\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Different regularization types\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg', 'sag'],  # Solvers supported by Logistic Regression\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model using random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best cross-validation accuracy\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Set Accuracy with Best Parameters:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbb954-62d0-466b-9324-da98f2e797a6",
   "metadata": {},
   "source": [
    "### 10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b1377-c335-42f9-bd2d-8457b0006f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model using One-vs-One strategy\n",
    "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
    "ovo_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = ovo_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"One-vs-One (OvO) Multiclass Logistic Regression Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be3a13-8853-4d35-97e0-852aa2cffedf",
   "metadata": {},
   "source": [
    "### 11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ae4c1-6d21-46d2-b0cb-096f780a83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model Accuracy:\", accuracy)\n",
    "\n",
    "# Generate and visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizing the confusion matrix with a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix for Binary Classification')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03261c-4668-498b-a08e-64d0ff66cef6",
   "metadata": {},
   "source": [
    "### 12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b6b66-6d98-416d-9eff-7f532659225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred, average='binary')  # Use 'macro' or 'weighted' for multiclass\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# Print the full classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692cabc5-aa2b-4ec9-87de-f33725388097",
   "metadata": {},
   "source": [
    "### 13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e903504-40e2-4b8a-b8b7-69583df18488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\\n\", y.value_counts())\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model with balanced class weights\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix with Class Weights')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f78103-6e81-46bd-a9e2-03b1a552f986",
   "metadata": {},
   "source": [
    "### 14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, andevaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d937b2-79ef-4731-9540-caaf35592ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = pd.read_csv('titanic.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Display initial missing values count\n",
    "print(\"Missing values before handling:\\n\", df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Fill missing Age values with the median age\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Embarked values with the mode (most frequent value)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop any remaining missing values (if any)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])  # Male = 1, Female = 0\n",
    "df['Embarked'] = label_encoder.fit_transform(df['Embarked'])  # Encode Embarked\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = df[features]\n",
    "y = df['Survived']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy on Titanic Dataset:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Titanic Dataset')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112bc5-2412-41d4-9b3b-a939d6508c8c",
   "metadata": {},
   "source": [
    "### 15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ea40e-f82b-4ae6-b53c-98368d40a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1️⃣ Logistic Regression without Feature Scaling\n",
    "model_without_scaling = LogisticRegression(max_iter=1000)\n",
    "model_without_scaling.fit(X_train, y_train)\n",
    "y_pred_without_scaling = model_without_scaling.predict(X_test)\n",
    "accuracy_without_scaling = accuracy_score(y_test, y_pred_without_scaling)\n",
    "print(\"Accuracy without Feature Scaling:\", accuracy_without_scaling)\n",
    "\n",
    "# 2️⃣ Apply Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with Feature Scaling\n",
    "model_with_scaling = LogisticRegression(max_iter=1000)\n",
    "model_with_scaling.fit(X_train_scaled, y_train)\n",
    "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
    "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
    "print(\"Accuracy with Feature Scaling:\", accuracy_with_scaling)\n",
    "\n",
    "# 3️⃣ Compare Results\n",
    "if accuracy_with_scaling > accuracy_without_scaling:\n",
    "    print(\"Feature scaling improved the model's accuracy.\")\n",
    "elif accuracy_with_scaling == accuracy_without_scaling:\n",
    "    print(\"Feature scaling had no impact on the model's accuracy.\")\n",
    "else:\n",
    "    print(\"Feature scaling decreased the model's accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f4a2e-1f06-4bcc-b9a4-eb2eee624784",
   "metadata": {},
   "source": [
    "### 16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb4899-8025-44be-9e06-b13862653a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for ROC AUC calculation\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd351a0b-0bff-48d6-9b66-55824a85a59a",
   "metadata": {},
   "source": [
    "### 17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d8a95-6c4b-47b1-b5f0-25d520fa3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model with custom regularization strength (C=0.5)\n",
    "model = LogisticRegression(C=0.5, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model Accuracy with C=0.5:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92def7cf-8a54-4697-9fda-ea2d1c230cd8",
   "metadata": {},
   "source": [
    "### 18.Write a Python program to train Logistic Regression and identify important features based on model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edde9b-5c05-4fc1-987f-a14a31f3d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance from model coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "# Print the most important features\n",
    "print(\"Feature Importance Based on Coefficients:\\n\", feature_importance)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color='skyblue')\n",
    "plt.title('Feature Importance Based on Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012a56b-829f-44b3-8373-104cdf5d38fa",
   "metadata": {},
   "source": [
    "### 19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c32f0-7107-4741-bf2c-a53abf631483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1) \n",
    "y = df['reveiw_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance using Cohen's Kappa Score\n",
    "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Cohen's Kappa Score:\", kappa_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbe49e-dcb4-4adf-8c6f-f3914670ab30",
   "metadata": {},
   "source": [
    "### 20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f6f10-348c-4c06-a226-c07da680d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate precision-recall values\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "average_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "# Plot the Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.', label=f'AP = {average_precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Logistic Regression')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print average precision score\n",
    "print(\"Average Precision Score:\", average_precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88db44-0974-44de-8a26-e57414e1ec4e",
   "metadata": {},
   "source": [
    "### 21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210ba4b-fc5d-4bc9-8dd9-1c29aae85560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['reveiw_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of solvers to test\n",
    "solvers = ['liblinear', 'saga', 'lbfgs']\n",
    "accuracy_results = {}\n",
    "\n",
    "# Train and evaluate model using different solvers\n",
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[solver] = accuracy\n",
    "    print(f\"Accuracy with solver '{solver}': {accuracy:.4f}\")\n",
    "\n",
    "# Compa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3705a-444d-41c0-8c6e-a6b264feac8f",
   "metadata": {},
   "source": [
    "### 22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317f8ed-0cd7-4f25-9fe6-2d34e91cf046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance using MCC and Accuracy\n",
    "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e0ee8-a040-4dab-bcd8-02042c2ff747",
   "metadata": {},
   "source": [
    "### 23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145db23-b040-469b-ab95-36c24f35cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1️⃣ Train Logistic Regression on Raw Data\n",
    "model_raw = LogisticRegression(max_iter=1000)\n",
    "model_raw.fit(X_train, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "print(\"Accuracy on Raw Data:\", accuracy_raw)\n",
    "\n",
    "# 2️⃣ Apply Standardization (Feature Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression on Standardized Data\n",
    "model_scaled = LogisticRegression(max_iter=1000)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(\"Accuracy on Standardized Data:\", accuracy_scaled)\n",
    "\n",
    "# 3️⃣ Compare Results\n",
    "if accuracy_scaled > accuracy_raw:\n",
    "    print(\"Feature scaling improved the model's accuracy.\")\n",
    "elif accuracy_scaled == accuracy_raw:\n",
    "    print(\"Feature scaling had no impact on the model's accuracy.\")\n",
    "else:\n",
    "    print(\"Feature scaling decreased the model's accuracy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d8354-7825-45d5-8cf9-553b16517d3f",
   "metadata": {},
   "source": [
    "### 24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e0b51-f4ec-4df7-a25a-3244f9c22c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Apply Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for 'C' values\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Use GridSearchCV for cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameter and corresponding accuracy\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Optimal Regularization Strength (C): {best_C}\")\n",
    "print(f\"Cross-Validation Accuracy with Best C: {best_score:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy with Optimal C: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5a8ad-5cf8-4c8e-b728-9f02ffea4ff0",
   "metadata": {},
   "source": [
    "### 25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588fd7d1-9395-4b7d-833d-5f8f7abc34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib  # For saving and loading the model\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('amazon.csv')  # Replace with your actual dataset filename\n",
    "\n",
    "# Convert categorical data into numerical values using Label Encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop('review_content', axis=1)  # Replace 'target' with your actual target column name\n",
    "y = df['review_title']\n",
    "\n",
    "# Apply Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(model, 'logistic_regression_model.joblib')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('logistic_regression_model.joblib')\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluate the loaded model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Loaded Model:\", accuracy)\n",
    "\n",
    "# Predict on new data (example)\n",
    "# Replace this with actual new input data as needed\n",
    "new_data = X_test[0].reshape(1, -1)\n",
    "new_prediction = loaded_model.predict(new_data)\n",
    "print(\"Prediction for new data:\", new_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8c74c-a229-434e-bbaa-4ffc75f24184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
